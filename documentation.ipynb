{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "Code Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP\n",
    "Mithilfe von SHAP soll untersucht werden:\n",
    "\n",
    "- Welche Bildbereiche das Modell für die Klassifikation heranzieht.\n",
    "- Ob sich die wichtigen Merkmale je nach Pokémon-Klasse unterscheiden.\n",
    "- Wie sich die Modellentscheidungen bei gezielter Manipulation der Pokemons ändern.\n",
    "\n",
    "### Funktionsweise von SHAP\n",
    "SHAP berechnet Shapley-Werte, um den Einfluss einzelner Eingabe-Features auf die Modellvorhersage zu bewerten. Für Bilder identifiziert SHAP, welche Pixel oder Regionen am wichtigsten für eine Entscheidung sind. Dazu werden Bildbereiche maskiert und der Effekt auf die Vorhersage wird analysiert.\n",
    "\n",
    "In diesem Projekt wurde der \"blur\"-Masker gewählt, der maskierte Bildbereiche durch unscharfe Versionen ersetzt. Dies ermöglicht eine natürliche Verzerrung der Bilder und bewahrt damit wichtige Strukturen.\n",
    "\n",
    "## Initialisierung von SHAP\n",
    "Importieren der benötigten Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import shap\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainiertes modell und datensatz laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_0.781.keras')\n",
    "dataset = load_dataset(\"keremberke/pokemon-classification\", 'full', split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (160, 160)\n",
    "image_shape = (160, 160, 3) \n",
    "\n",
    "def f(x):\n",
    "    tmp = x.copy()\n",
    "    return model(tmp)\n",
    "\n",
    "masker_blur = shap.maskers.Image(\"blur(32,32)\", image_shape)\n",
    "\n",
    "num_classes = len(dataset.features['labels'].names)\n",
    "explainer = shap.Explainer(f, masker_blur, output_names=list(range(num_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hilfsfunktionen\n",
    "\n",
    "Die Funktion analyze_image_url() führt folgende Schritte aus:\n",
    "- Preprocessing des Bildes.\n",
    "- Modellvorhersage des Bildes.\n",
    "- Berechnung und Visualisierung der SHAP-Werte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"samples/\"\n",
    "\n",
    "# Bild preprocessing\n",
    "def preprocess_image(image_path, target_size):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    return img_array\n",
    "\n",
    "# Bild analysieren\n",
    "def analyze_image(image_name):\n",
    "    x_test_sample = preprocess_image(image_folder + image_name, target_size)\n",
    "    \n",
    "    prediction = model(np.array([x_test_sample]))\n",
    "    prediction_probabilities = tf.nn.softmax(prediction).numpy()\n",
    "    predicted_class_idx = np.argmax(prediction_probabilities, axis=-1)[0]\n",
    "    predicted_class_name = sorted(dataset.features['labels'].names)[predicted_class_idx]\n",
    "    print(f\"Model Prediction: {predicted_class_name} (Class Index: {predicted_class_idx})\")\n",
    "\n",
    "    shap_values_ = explainer(np.array([x_test_sample]), max_evals=2000, batch_size=50, outputs=shap.Explanation.argsort.flip[:1])\n",
    "    shap.image_plot(shap_values_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des Modells\n",
    "### Pikachu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_image(\"pikachu.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ist deutlich zu erkennen das die wichtigte Eigenschaft für das Modell die roten Backen des Pikachus sind. Daher soll nun geprüft werden wie es sich verhält wenn diese nicht mehr vorhanden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_image(\"pikachu_no_cheeks.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entgegen der Annahme wird Pikachu immer noch korrekt erkannt. Stattdesssen fokussiert sich das Modell jetzt auf die Ohren. Zu beachten ist aber auch der niedrigere SHAP wert zu dem Plot davor.\n",
    "Als nächstes soll daher ein Bild ohne Ohren und Schwanz getestet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_image(\"pikachu_no_ears.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie erwartet ist der Fokus nun wieder auf den Roten backen. Diese scheinen also auschlaggebender zu sein als der eigentlich sehr charakteristische Schwanz oder die Ohren, sodass das Modell trotzdem auf Pikachu schließt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_image(\"pikachu_no_cheeks_ears.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch ohne die roten backen wird Pikachu aber noch korrekt erkannt. Hierbei liegt der Fokus auf dem Mund.\n",
    "Dem Modell scheint es daher vor allem um die rote Farbe zu gehen. Als letzter Test soll auch dieses Merkmal genommen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_image(\"pikachu_nothing.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie erwartet wird Pikachu nun nicht mehr erkannt. Das Wegnehmen aller charakteristischen Merkmale führt dazu, dass das Modell keine korrekte Zuordnung mehr treffen kann.\n",
    "\n",
    "Die Analyse der verschiedenen Pikachu-Bilder zeigt, dass das Modell stark auf die roten Backen fokussiert ist. Selbst wenn andere charakteristische Merkmale wie Ohren oder Schwanz entfernt werden, bleibt die Klassifikation korrekt, solange die roten Backen vorhanden sind. Interessant ist aber die verschiebung der fokussierung auf andere Merkmale, sobald ein Merkmal, in diesem Fall die Backen, weggenommen wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hitmonchan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_image(\"hitmonchan.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Analyse von Hitmonchan wird deutlich, das hier die roten Boxhandschuhe als deutlichstes Merkmal gewertet werden. Dies soll mit dem nächsten Bild noch bestätigt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_image(\"hitmonchan2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trotz einem verschwommenerem Fokus ist dieser noch zum größten Teil auf dem roten Boxhandschuh.\n",
    "Daher soll nun getestet werden was passiert wenn die Farbe dieses Handschuhs geändert wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_image(\"hitmonchan_blue.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tatsächlich reicht diese Änderung aus um dem Modell das wichtigste Merkmal des Pokemons zu nehmen und dadurch eine korrekte Erkennung zu verhindern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gengar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_image(\"660a1122583033a20cf90ce9dccbe2c2.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ist ein sehr deutlicher Fokus auf die roten Augen zu erkennen. Im nächsten Bild soll daher Gengar mit geschlossenen Augen getestet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_image(\"rhw55lui8dz21.webp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tatsächlich reichen hier die geschlossenen Augen aus um ein falsches Resultat zu bekommen. \n",
    "Im gegensatz zu Pikachu haben hier also die anderen Merkmale, wie beispielsweise die eigentlich auch sehr charakteristischen Ohren, einen geringen Stellenwert.\n",
    "Dies ist damit zu erklären, dass der Datensatz zu Gengar fast auschließlich aus Bildern mit den Roten Augen besteht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME\n",
    "Import Libraries and create needed objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Load model\n",
    "model = tf.keras.models.load_model('model_0.781.keras')\n",
    "#Instance of the LIME explainer\n",
    "explainer = lime_image.LimeImageExplainer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function that preprocesses an image-array (normalization) and returns the model's prediction probabilities for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(img_array):\n",
    "\n",
    "    img_array = img_array.astype(float) / 255.0\n",
    " \n",
    "    return model.predict(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Function generates an explanation for an image classification prediction using LIME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_prediction(image, top_labels=1, num_features=100000, num_samples=1000):\n",
    " \n",
    "    \n",
    "    # Generate explanation\n",
    "    explanation = explainer.explain_instance(\n",
    "        image,\n",
    "        model_predict,\n",
    "        hide_color=None,\n",
    "        num_features=num_features,\n",
    "        num_samples=num_samples,\n",
    "        segmentation_fn=SegmentationAlgorithm('quickshift',\n",
    "                                              kernel_size=2,\n",
    "                                              max_dist=100,\n",
    "                                              ratio=0.5)\n",
    "    )\n",
    "\n",
    "    \n",
    "    temp, mask = explanation.get_image_and_mask(\n",
    "        explanation.top_labels[0],\n",
    "        positive_only=True,\n",
    "        num_features=6,\n",
    "        hide_rest=True  \n",
    "    )\n",
    "\n",
    "    return explanation, temp, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function displays the input image and the LIME explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_explanation(image, explanation_result):\n",
    "    temp, mask = explanation_result\n",
    "    temp = temp.astype(np.uint8)\n",
    "    image = image.astype(np.uint8)\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Original Image')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(temp)\n",
    "    plt.title('LIME Explanation')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loads image from web or local path and returns it as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_to_array(url, fromWeb, target_size=(160, 160)):\n",
    "    if fromWeb:\n",
    "        img = load_image_from_web(url)\n",
    "    else:\n",
    "        img = Image.open(url)\n",
    "        \n",
    "    if img is None:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    img_resized = img.resize(target_size)\n",
    "    img_array = np.array(img_resized)\n",
    "\n",
    "\n",
    "    if img_array.shape[-1] != 3:  \n",
    "        raise ValueError(\"Input image must have 3 channels (RGB).\")\n",
    "\n",
    "    return img_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "def load_image_from_web(url):  \n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "\n",
    "        return img\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combines the functions above to load an image from a local path and explain the model's prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_local_and_explain(url):\n",
    "    image = load_image_to_array(url, False)\n",
    "    explanation, temp, mask = explain_prediction(image)\n",
    "    show_explanation(image, (temp, mask))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pidgeot and Pidgeotto look really similiar. One major difference are the feathers on top of their head. The following plots show that the model uses these feathers to classify the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"_____Pidgeot_____\")\n",
    "load_image_from_local_and_explain('samples/Pidgeot2.jpg')\n",
    "load_image_from_local_and_explain('samples/Pidgeot3.jpg')\n",
    "print(\"_____Pidgeotto_____\")\n",
    "load_image_from_local_and_explain('samples/Pidgeotto1.jpg')\n",
    "load_image_from_local_and_explain('samples/Pidgeotto2.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aerodactyl is often falsely predicted to be Mewto. One possible reason could be the similiar skin color in some pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_image_from_local_and_explain('samples/Aerodactyl2.jpg')\n",
    "load_image_from_local_and_explain('samples/Mewtwo1.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlWeb = 'https://www.pokemon.com/static-assets/content-assets/cms2/img/pokedex/full/004.png'\n",
    "urlLocal = 'C:\\\\Users\\\\b43566\\\\Desktop\\\\Studium\\\\Vorlesungen\\\\5.Semester\\\\Vorlesungen\\\\XAI\\\\archive\\\\PokemonData\\\\Mewtwo\\\\00000024.jpg'\n",
    "image = load_image_to_array(urlLocal, False)\n",
    "explanation, temp, mask = explain_prediction(image)\n",
    "show_explanation(image, (temp, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pokemon Clefairy and Clefable are also very similiar. The model seems to use the spikes or wings on the back of clefable to detect clefable and tell them apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"_____Clefairy_____\")\n",
    "load_image_from_local_and_explain('samples/clefairy1.jpg')\n",
    "load_image_from_local_and_explain('samples/clefairy2.jpg')\n",
    "\n",
    "\n",
    "print(\"_____Clefable_____\")\n",
    "load_image_from_local_and_explain('samples/clefable1.jpg')\n",
    "load_image_from_local_and_explain('samples/clefable2.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quellenangaben\n",
    "- Ukwuoma, C. C., Cai, D., Eziefuna, E. O., Oluwasanmi, A., Abdi, S. F., Muoka, G. W., Thomas, D., & Sarpong, K. (2025). Enhancing histopathological medical image classification for early cancer diagnosis using deep learning and explainable AI – LIME & SHAP. Biomedical Signal Processing and Control, 100(Part C), 107014. https://doi.org/10.1016/j.bspc.2024.107014\n",
    "- den Broeck,  G. V.;  Lykov,  A.;  Schleich,  M.;  and Suciu,  D. 2022.  On the Tractability ofSHAP Explanations.J. Artif. Intell. Res.74:  851–886. https://doi.org/10.1613/jair.1.13283.2\n",
    "- Oveis, M. (2024, January 26). Easy guide: Using SHAP algorithm to explain CNN classification of SAR images (MSTAR database). Medium. https://medium.com/@oveis/easy-guide-using-shap-algorithm-to-explain-cnn-classification-of-sar-images-mstar-database-8138657585c8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
